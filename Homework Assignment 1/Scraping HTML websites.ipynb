{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name: JANMEJAY MOHANTY\n",
    "# CWID: 20009315\n",
    "# Course: BIA 660 WS WEB MINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read this first: https://www.w3schools.com/html/default.asp\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import time\n",
    "import requests\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run(url):\n",
    "\n",
    "    fw=open('reviews.csv','w',encoding='utf8') # output file\n",
    "\n",
    "    writer=csv.writer(fw,lineterminator='\\n') # create a csv writer for this file\n",
    "    \n",
    "    for i in range(5): # try 5 times\n",
    "            # send a request to access the url\n",
    "            response=requests.get(url,headers = { 'User-Agent': 'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36', })\n",
    "            if response: # explanation on response codes: https://realpython.com/python-requests/#status-codes\n",
    "                break # we got the file, break the loop\n",
    "            else:\n",
    "                print('fail',i)\n",
    "                time.sleep(2) # wait 2 secs\n",
    "            \n",
    "   \n",
    "    # all five attempts failed, return  None\n",
    "    if not response: return None\n",
    "    \n",
    "    html=response.text # read in the text from the file\n",
    "    \n",
    "    soup = BeautifulSoup(html,'html') # parse the html \n",
    "\n",
    "    reviews=soup.findAll('div', {'class':re.compile('review_table_row')}) # get all the review divs\n",
    "\n",
    "    for review in reviews:\n",
    "       \n",
    "        critic,text,date,platform,rating='NA','NA','NA','NA','NA' # initialize critic, text, date, platform and rating\n",
    "\n",
    "        criticChunk=review.find('a',{'href':re.compile('/critics/')})   # critic name\n",
    "        if criticChunk: critic=criticChunk.text.strip()\n",
    "        \n",
    "        textChunk=review.find('div',{'class':'the_review'})   # review text\n",
    "        if textChunk: text=textChunk.text.strip()\n",
    "\n",
    "        dateChunk=review.find('div',{'class':'review-date'})    # review date\n",
    "        if dateChunk: date=dateChunk.text.strip()\n",
    "\n",
    "        platformChunk=review.find('em',{'class':'critic-publication'})   # review platform\n",
    "        if platformChunk: platform=platformChunk.text.strip()\n",
    "\n",
    "        ratingChunk = review.find('div',{'class': re.compile('review_icon')})   # review rating\n",
    "        ratingValue = str(ratingChunk)\n",
    "        if (ratingValue.find('rotten')>0):\n",
    "            rating = 'rotten'\n",
    "        if (ratingValue.find('fresh')>0):\n",
    "            rating= 'fresh'\n",
    "        writer.writerow([critic,text,date,platform,rating]) # write to file \n",
    "        \n",
    "    fw.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.rottentomatoes.com/m/terminator_2_judgment_day/reviews'\n",
    "run(url)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "79f58b2da1d0ebeef0843b536b913fe6ecf5d6027e7f201d25bafe70c90b7910"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
